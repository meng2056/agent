import json
import re
from typing import Optional, Any
from pydantic import BaseModel, Field
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.prompts import ChatPromptTemplate
from ai.RACG.chunking.config.log_confg import logger
from ai.RACG.chunking.chunker import SemanticNode
from ai.RACG.chunking.config.racg_prompt import PROMPT_TEMPLATE
from ai.ai_config.config import gen_qwq_coder_480b


class CommentGenerator:

    def __init__(self):
        self.llm = gen_qwq_coder_480b(
                tokens=2000,
                streaming=False
            )

    def generate(self, node: SemanticNode, language: str) -> Optional[str]:

        try:
            prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)
            chain = (prompt_template
                     | self.llm.bind(response_format={"type": "json_object"})
                     | JsonOutputParser())

            context = {
                "language": language,
                "node_name": node.name,
                "node_type": node.type,
                "existing_comment": node.existing_comment or "None",
                "source_code": node.source_code
            }

            result = chain.invoke(context)

            comment = self._validate_and_fix(
                json_data=result,
                excepted_name=node.name,
                chain=chain,
                context=context
                )
            return comment if comment else None

        except Exception as e:
            logger.error(f"LLM gen faile. Node[{node.name}]: {e}")
            return None

    def _validate_and_fix(self,
                          json_data: dict[str, Any],
                          excepted_name: str,
                          chain,
                          context: dict,
                          max_retries: int = 3) -> str:
        current_relust = json_data

        for attempt in range(1, max_retries + 1):
            comment = self._validate(current_relust, excepted_name)
            if comment is not None:
                return comment

            if attempt < max_retries:
                logger.warning(
                    f"Name mismatch detected (attempt {attempt}/{max_retries}). "
                    f"Retrying LLM invocation for node '{excepted_name}'..."
                )
                try:
                    current_relust = chain.invoke(context)
                except Exception as e:
                    logger.error(f"Retry {attempt} failed: {e}")
                    continue
            else:
                logger.warning(
                    f"Name mismatch persists after {max_retries} attempts. "
                    f"Falling back to key correction for node '{excepted_name}'."
                )

        return self._fix_name_mismatch(current_relust, excepted_name)

    @staticmethod
    def _validate(json_data: dict[str, Any], expected_name: str) -> Optional[str]:
        if not json_data or not isinstance(json_data, dict):
            return None

        keys = list(json_data.keys())
        if not keys:
            return None

        gen_keys = keys[0]
        if gen_keys == expected_name:
            return str(json_data[gen_keys])
        return None

    @staticmethod
    def _fix_name_mismatch(json_data: Optional[dict[str, Any]],
                           expected_name: str) -> str:
        if not json_data or not isinstance(json_data, dict):
            logger.warning(
                f"Node[{expected_name}] LLM returned empty JSON after retries")
            return ""

        keys = list(json_data.keys())
        if not keys:
            return ""

        worong_key = keys[0]
        comment = json_data[worong_key]
        logger.warning(
            f"Final name illusion fix: key '{keys}' → '{expected_name}'. "
            f"Comment extracted successfully."
        )
        return str(comment)

    # @staticmethod
    # def _validate_and_fix(
    #         json_data: dict[str, Any],
    #         expected_name: str
    # ) -> str:
    #
    #     if not json_data:
    #         logger.warning(f"Node[{expected_name}] LLM return empty JSON")
    #         return ""
    #
    #     keys = list(json_data.keys())
    #     if not keys:
    #         return ""
    #
    #     generated_key = keys[0]
    #     comment_content = json_data[generated_key]
    #
    #     if generated_key != expected_name:
    #         logger.warning(
    #             f"Name illusion detection: Generated by LLM "
    #             f"Key='{generated_key}' != truth Name='{expected_name}'。"
    #             f"The error has been automatically corrected。"
    #         )
    #         return str(comment_content)
    #
    #     logger.info(f"Generated comment for {expected_name}")
    #     return str(comment_content)


class CommentAdapter:
    @staticmethod
    def insert_comments(source_code: str,
                        nodes_with_comments: list[tuple[SemanticNode, str]],
                        language: str) -> str:

        sorted_nodes = sorted(
            nodes_with_comments, key=lambda x: x[0].start_byte, reverse=True
        )

        lines = source_code.splitlines(keepends=True)

        modified_lines = lines.copy()

        for node, comment in sorted_nodes:
            if not comment:
                continue

            target_line_idx = node.start_line
            if target_line_idx < len(lines):
                target_line_content = lines[target_line_idx]
                indentation = (re.match(r"^\s*", target_line_content)
                               .group(0))
            else:
                indentation = ""

            formatted_comment = CommentAdapter._format_comment(
                comment, language, indentation
            )

            modified_lines.insert(target_line_idx, formatted_comment)

        return "".join(modified_lines)

    @staticmethod
    def _format_comment(content: str, language: str, indentation: str) -> str:

        content_lines = content.strip().split('\n')
        # indented_content = '\n'.join([f"{indentation}{line}"
        #                               for line in content_lines])

        if language == 'python':

            indented_lines = [f"{indentation}# {line}" for line in
                              content_lines]
            return '\n'.join(indented_lines) + '\n'
            # return (f"{indentation}\"\"\"\n{indented_content}\n"
            #         f"{indentation}\"\"\"\n")

        elif language == 'verilog' or language == 'systemverilog':
            indented_content = '\n'.join(
                [f"{indentation}{line}" for line in content_lines])
            return f"{indentation}/*\n{indented_content}\n{indentation}*/\n"
            # return f"{indentation}/*\n{indented_content}\n{indentation}*/\n"

        else:
            return f"{indentation}// {content}\n"


def enrich_code_with_comments(
        source_code: str, nodes: list[SemanticNode], language: str
) -> str:

    generator = CommentGenerator()
    nodes_with_comments = []

    for node in nodes:
        comment = generator.generate(node, language)
        if comment:
            nodes_with_comments.append((node, comment))

    if not nodes_with_comments:
        return source_code

    return CommentAdapter.insert_comments(
        source_code, nodes_with_comments, language
    )